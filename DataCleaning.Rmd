---
title: "Data Cleaning and Preparation"
author: "Nicole LaPointe Jameson"
date: "March 6, 2016"
output: html_document
---

### Establishing the Workbench
```{r, message=FALSE}
#Set Seed for randomization subsampling
set.seed(2145)

#Packages Used
library(EBImage)
library(Momocs)
library(data.table)
library(XML)
```

### Specify directories

```{r, eval=FALSE}

setwd("C:\\Users\\NMLJ\\Documents\\GitHub\\Project3\\AnimalImg")

#Sample size for Train: 70%
7373*.70
#5161 is 70%

#Paritioning of Data
full_set <- dir()

dir_images <- "C:\\Users\\NMLJ\\Documents\\GitHub\\Project3\\AnimalImg"
dir_names <- list.files(dir_images)

```

###Create Breed Labels
```{r}
breed_name <- rep(NA, length(dir_names))
for(i in 1:length(dir_names)){
  tt <- unlist(strsplit(dir_names[i], "_"))
  tt <- tt[-length(tt)]
  breed_name[i] = paste(tt, collapse="_", sep="")
}
cat_breed <- c("Abyssinian", "Bengal", "Birman", "Bombay", "British_Shorthair", "Egyptian_Mau",
               "Maine_Coon", "Persian", "Ragdoll", "Russian_Blue", "Siamese", "Sphynx")

iscat <- breed_name %in% cat_breed
y_cat <- as.numeric(iscat)

#Combined Matrix of Image and Breed

imgAndBreed <- cbind(dir_names,breed_name)

write(imgAndBreed, file="C:\\Users\\NMLJ\\Documents\\GitHub\\cycle3cvd-team8\\data\\imgAndBreed.R")

```


###Training and Testing set Creation
```{r}

train_set <- sample(imgAndBreed, 5161, replace=FALSE)
test_set <- imgAndBreed[!imgAndBreed %in% train_set]

write(train_set, file="C:\\Users\\NMLJ\\Documents\\GitHub\\cycle3cvd-team8\\data\\train\\train_Set.R")

write(test_set, file="C:\\Users\\NMLJ\\Documents\\GitHub\\cycle3cvd-team8\\data\\test\\test_Set.R")

##FIRST EDIT: Write Images to Train and Test Set Files

img_train_dir <- "C:\\Users\\NMLJ\\Documents\\GitHub\\cycle3cvd-team8\\data\\train\\"

img_test_dir <- "C:\\Users\\NMLJ\\Documents\\GitHub\\cycle3cvd-team8\\data\\test\\"
```

###Add in Annotations

```{r}

setwd("C:\\Users\\NMLJ\\Documents\\GitHub\\Project3\\annotations\\xmls")

temp <- list.files(pattern="*.xml")

myxml <- lapply(temp,xmlParse)
for(i in 1: length(myxml)){
  myxml[[i]] <- xmlToDataFrame(myxml[[i]], nodes=getNodeSet(myxml[[i]],"//annotation/object/bndbox"))
}

print(myxml)


#COMBINING MATRIX with Image, XML annot and Breed

```


###Resizing Images


```{r}
library(EBImage)

#Resizing Train Images

setwd("C:\\Users\\NMLJ\\Documents\\GitHub\\cycle3cvd-team8\\train")

temptrain <- list.files(pattern="*.jpeg")

#ERROR: Needs to be array

for(i in 1: length(train_set)){
  img_resize_train[[i]] <- resize(train_set[[i]], 128, 128)
}


```



### Construct visual feature

*NEED TO DO*

```{r}
source("C:\\Users\\NMLJ\\Documents\\GitHub\\cycle3cvd-team8\\lib\\feature.R")

tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "img_zip_train"))
tm_feature_test <- system.time(dat_test <- feature(img_test_dir, "img_zip_test"))

save(dat_train, file="./output/feature_train.RData")
save(dat_train, file="./output/feature_test.RData")

```

### Train a classification model with training images
Call the train model and test model from library. 
```{r}
source("./lib/train.R")
source("./lib/test.R")
```

### Model selection with cross-validation
* Do model selection by choosing among different values of training model parameters, that is, the interaction depth for GBM in this example. 
```{r, eval=FALSE}
source("./lib/cross_validation.R")
depth_values <- seq(3, 11, 2)
err_cv <- array(dim=c(length(depth_values), 2))
K <- 5  # number of CV folds
for(k in 1:length(depth_values)){
  cat("k=", k, "\n")
  err_cv[k,] <- cv.function(dat_train, label_train, depth_values[k], K)
}
save(err_cv, file="./output/err_cv.RData")
```

```{r, echo=FALSE}
depth_values <- seq(3, 11, 2)
load("./output/err_cv.RData")
```

* Visualize CV results
```{r}
#pdf("./fig/cv_results.pdf", width=7, height=5)
plot(depth_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
     main="Cross Validation Error", type="n", ylim=c(0, 0.15))
points(depth_values, err_cv[,1], col="blue", pch=16)
lines(depth_values, err_cv[,1], col="blue")
arrows(depth_values, err_cv[,1]-err_cv[,2],depth_values, err_cv[,1]+err_cv[,2], 
      length=0.1, angle=90, code=3)
#dev.off()
```

* Choose the "best" parameter value
```{r}
depth_best <- depth_values[which.min(err_cv[,1])]
par_best <- list(depth=depth_best)
```

* Train the model with the entire training set using the selected model (model parameter) via cross-validation.
```{r}
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
save(fit_train, file="./output/fit_train.RData")
```

### Make prediction 
Feed the final training model with the completely holdout testing data. 
```{r}
tm_test <- system.time(pred_test <- test(fit_train, dat_test))
save(pred_test, file="./output/pred_test.RData")
```

### Summarize Running Time
Prediction performance matters, do does the running times for constructing features and for training the model, especially when the computation resource is limited. 
```{r}
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for making prediction=", tm_test[1], "s \n")
```