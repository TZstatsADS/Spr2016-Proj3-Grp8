---
title: "The Paw-sitively Best Classification Model"
author: "Team 8: Eric Ho, Xuan Zuo, Zehao Wang, Nicole LaPointe Jameson"
output: 
  html_document:
    theme: spacelab
    highlight: espresso
    toc: true
    toc_float:
      collapsed: true
---
#Introduction and Initial Goals

![Cat Vs. Dog! GRRR](https://i.ytimg.com/vi/IiilA0dsciY/maxresdefault.jpg)

We set out to find a model that balances quite a few factors. The group decided to look at numerous components of what makes a model "good" which finally concluded with:


1. Good performance 
    + Greater than 65% accuracy
2. Fast computation time
3. Ease of conceptual understanding
    + To better convey what is happening to colleages as well as the client
4. Parsimonious
    + Or ease of reproducability. Code that isnt complex, easily adaptible


To carry out these goals, we decided to take the approach of fitting a **variety of models** on a **baseline feature**, then carried out a quasi- forward stepwise selection of all the models with their added features, removed or kept based on their ranking on the above four components.

***

#Setting Up The Environment

##Packages Used
The following packages were used in our project

```{r, message=FALSE, warning=FALSE}
library(MASS)
library(mda)
library(rpart)
library(EBImage)
library(gbm)
library(neuralnet)
library(grid)
library(Momocs)
library(data.table)
library(XML)
library(jpeg)
```

##Data Cleaning Overview

1. Image Removal
  + All images that were not properly formatted or compressed as .jpg were removed (14 total, list of which can be found on piazza). We also removed the trimap folder.
2. Data Partioning/Relevant Preprocessing
  + We then partitioned the data into a testing and training set, where the training set was finally established to **70%**, and the testing set was finally set to **30%** (after playing with paritions from 60/40 to 90/10) based on the best results, and avoidance of fitting to individual predictor noise.
3. Breed Labels
  + Running the provided loop, we created breed labels, and produced a binary indexing vector of if each image was a cat or dog for both training and testing sets, to aid in supervised modeling.
4. XML Annotations
  + We also pulled the XML annotations from the images using a loop function as well, but ended up not using these in the final model. 
5. Uniform Resizing
  + We wished to see if the loss in picture granulairty would aid in speed and performance, but this new "data set" of resized images was not used for the final model either.

***

#Baseline Feature: Color Histograms
The first feature we decided on to use as our baseline feature for all the models was the color histograms of RGB values pulled from each image. We determined from some analysis that dogs tended to have more green in their histograms, while cats had more blue values. We did not resize the images before carrying this out to imporve accuracy and not lose information.

The Histograms looked like this:
```{r, echo=FALSE}
setwd("C:\\Users\\NMLJ\\Documents\\GitHub\\Project3\\AnimalImg\\")
img_dir <- "C:\\Users\\NMLJ\\Documents\\GitHub\\Project3\\AnimalImg\\"
img_names <- list.files(img_dir)
img.1 <- readImage(list.files(img_dir)[1])
hist(img.1)

setwd("C:\\Users\\NMLJ\\Documents\\GitHub\\cycle3cvd-team8\\cycle3cvd-team8\\")

```

We kept this feature in our final model.

##Second Final Feature: Contour Plot Values

###Intuition

After also carrying out research in biological differences between cats and dogs, we realized certain features (such as tongue shape, or eye shape), would be harder to pull code-wise and time-wise, even though accuracy might improve. However, the shape of the animal was something we were able to execute with a decent improvement in accuracy as well as not adding too much time. 

###Execution

Here is a snippet of the loop on one single image:

```{r, error=FALSE, message=FALSE}
img2 <- readImage("C:\\Users\\NMLJ\\Documents\\GitHub\\Project3\\train\\american_bulldog_24.jpg")
img2 <- resize(img2, 128, 128)
img2 <- channel(img2, mode="gray")
img3 <- thresh(img2, w=50, h=50, offset=0.05)
oc1 <- ocontour(bwlabel(img3))

#Metric Used: Summation of the contour values

display(img3)
```

##Third final feature: Pixel Brightness Intensity

###Intuition

Under the hunch that dogs and cats tend to be photographed in different type of light environments, (such as dogs are more likely to be outside), we took a random sample (n=30) of images, and tested to see if the difference between the mean brightness itensity between dogs and cats was different. The results were statistically significant (p <.05), so we used this as another feature.

###Execution
```{r, error=FALSE, message=FALSE}
img950 <- readImage("C:\\Users\\NMLJ\\Documents\\GitHub\\Project3\\train\\Ragdoll_191.jpg")
colorMode(img950) = Grayscale

intens950 <- getFrame(img950,1)

#Mean value was extracted
print(mean(intens950))

#Produces images like this:
display(img950)
```

And the histograms produced appeared like this:
```{r, echo=FALSE}

hist(img950)

```


#The Models Used, Why, And How They Were Tuned 
The goal was to establish a variety of modeling methods on a few good features to maximize all of our goals.

We were very cautious in regards to **over-fitting**, which is when the output of your model is too exact. It correctly predicts every sample, and learns not only the general patterns but also each samples unique noise.

###SVM
Support Vector Machine, or SVM is a supervised learning algorithm that aims to maximize the margin of the training data (or, maximize the support vectors). Feature selection is very important with SVM becuase minimizing SSE can be influenced by just one observation. 

It is good in that it does carry out automatic feature selection. In layman's terms, it creates a "funnel" (or hyperplane) around a regression line, and residual values that fall within that funnel are not included in the paramter estimation.

###GBM
GBM, or generalized/gradient boosted regression model is a boosted regression tree model, that we carried out backwards stepwise regression with to pick features. 

We started with a high number of trees and decreased that value until finding the optimal value.


###MARS
A MARS model, or multivariate adaptive regression splines, is a non-parametric gregression tehcnique that automatically models nonlinearities and interactions between variables. It is a nonlinear statistical piecewise model.

The model function is based on hinge functions of a predictor. When this enters the model, the new features are then added to a basic linear regression model to estimate the slopes and intercepts between the outcome features. 

Unlike SVM, it is interpretable, and it does automatic feature selection.

###Model Tree
A Tree model partitions data into smaller groups that are more homogenous with respect to the response. Through tuning and training, one can dtermine the predictor to split on, the depth/complexity of the tree, and the prediction equation in terminal nodes.

To tune the tree, we tried splits10,20,30,40,50 and 50 was best based on accuracy performance. The tree is not the most reproducable or interpretible though.

###Neural Net
The neural net is an unsupervised technique that is essentially a black box; you put in your input, who knows what happens to get the output!
More generally (and superficially), the NN aims to minimize an alternative version of the sum of the squared errors of a given lambda. After training,lambda (regularization value) falls between 0 and .1.


##Overall Summary Table

![Results](http://i.imgur.com/HwEgC4b.jpg)

#Cross Validation Methods
We used the same cross-validation methods after training and tuning each model (when applicable). The method we selected was **K-Fold Cross Validation**.

![K-Fold Cross Validation Graphic](http://i.imgur.com/l6sN53u.jpg)

##The Method
To carry out this CV, one splits the data into K blocks of equal size. You then leave out first block and fit a model to predict the held-out block on. Performance of this validation based on hold-out predictions.The number (K) of folds is usually between 5-10. We opted for 5 after looking at performance. 

#The Final Model

Based on all of the above information and the combined balance of the four ideal components, we will be utilizing the **tree model**.

